<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Wang Rui - Research CV</title>
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #333; max-width: 900px; margin: 0 auto; padding: 40px 20px; background-color: #f9f9f9; }
        .container { background-color: #fff; padding: 40px; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-bottom: 20px; }
        h2 { color: #2980b9; margin-top: 30px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
        h3 { color: #34495e; margin-bottom: 5px; }
        p { margin: 5px 0; }
        .contact-info { margin-bottom: 30px; display: flex; flex-wrap: wrap; gap: 15px; font-size: 0.95em; }
        .contact-info a { color: #3498db; text-decoration: none; }
        .contact-info a:hover { text-decoration: underline; }
        .section-item { margin-bottom: 20px; }
        .date-location { font-size: 0.9em; color: #7f8c8d; font-style: italic; margin-bottom: 10px; }
        ul { padding-left: 20px; margin-top: 5px; }
        li { margin-bottom: 5px; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Wang Rui - Research CV</h1>
            <div class="contact-info">
                <span><strong>Birth:</strong> 30th October 1993</span>
                <span><strong>Email:</strong> <a href="mailto:rui.wang@g.sp.m.is.nagoya-u.ac.jp">rui.wang@g.sp.m.is.nagoya-u.ac.jp</a></span>
                <span><strong>Languages:</strong> Chinese, Japanese, English</span>
                <span><strong>Scholar:</strong> <a href="https://scholar.google.com/citations?user=N3UBXW8AAAAJ&hl=en&authuser=2" target="_blank">Google Scholar Profile</a></span>
            </div>
        </header>

        <section>
            <h2>Summary</h2>
            <p>I have several years of research experience in speech signal processing, focusing on spatial hearing and speech enhancement in challenging environments. At JAIST, I worked on monaural 3D sound localization using HRTF features under Prof. Masashi Unoki. For my Ph.D. at Nagoya University with Prof. Tomoki Toda, my main topic was directional target speaker extraction (TSE) in noisy and underdetermined conditions, resulting in publications such as TASLP. My future goal is to extend statistical signal processing (such as independent/low-rank and spatial covariance modeling) by coupling it with DNN priors and latest LLM-based context, aiming for identifiable, sample-efficient, and real-time/low-latency streaming speech enhancement.</p>
        </section>

        <section>
            <h2>Tools & Skills</h2>
            <p><strong>Programming:</strong> Python, Shell, C#, Matlab</p>
            <p><strong>Research Areas:</strong> Spatial audio, Speech signal processing, Speech enhancement/separation, Target speaker extraction, Deep learning</p>
        </section>

        <section>
            <h2>Work Experience</h2>
            <div class="section-item">
                <h3>Midea Group, AI Research Institute</h3>
                <p class="date-location">2025.5- | Shanghai, China</p>
                <p><strong>Research Engineer:</strong> Research on robust multi-task speech interaction system in challenge environments</p>
            </div>
            <div class="section-item">
                <h3>Nippon Telegraph and Telephone Corporation (NTT), CS lab</h3>
                <p class="date-location">2022.3-2022.4 | Tokyo, Japan</p>
                <p><strong>Winter internship:</strong> Research on robust speech separation</p>
            </div>
            <div class="section-item">
                <h3>National Institute of Information and Communications Technology (NICT), ASTREC</h3>
                <p class="date-location">2021.8-2021.10 | Kyoto, Japan</p>
                <p><strong>Summer internship:</strong> Research on robust speech recognition</p>
            </div>
        </section>

        <section>
            <h2>Education & Research</h2>
            <div class="section-item">
                <h3>Nagoya University</h3>
                <p class="date-location">2021.4-2025.3 | Nagoya, Japan</p>
                <p><strong>Doctor's degree:</strong> Computer Science, focus on target speaker extraction in challenge environments</p>
                <p><em>Toda Laboratory of speech</em></p>
            </div>
            <div class="section-item">
                <h3>Japan Advanced Institute of Science and Technology (JAIST)</h3>
                <p class="date-location">2018.10-2021.3 | Ishikawa, Japan</p>
                <p><strong>Master's degree:</strong> Computer Science, focus on HRTF-based DOA estimation and spatial hearing</p>
                <p><em>Akagi & Unoki Laboratory of speech</em></p>
            </div>
            <div class="section-item">
                <h3>National Institute of Metrology, China</h3>
                <p class="date-location">2016.9-2018.8 | Beijing, China</p>
                <p><strong>Master's course:</strong> Fluid Mechanics (Dropout due to lack of interest)</p>
            </div>
            <div class="section-item">
                <h3>China Jiliang University</h3>
                <p class="date-location">2012.9-2016.6 | Hangzhou, China</p>
                <p><strong>BS degree:</strong> Measurement and Control Technology and Instruments</p>
            </div>
        </section>

        <section>
            <h2>Publications & Awards</h2>
            <h3>Journal Papers</h3>
            <ul>
                <li>[2024] R. Wang, T. Fujimura, and T. Toda, "Target Speaker Extraction under Noisy Underdetermined Conditions Using Conditional Variational Autoencoder, Global Style Token, and Neural Postfilter," APSIPA Transactions on Signal and Information Processing, Vol. 14, No. 1, e2, pp. 1-26, Jan. 2025.</li>
                <li>[2024] R. Wang, L. Li, T. Toda, "Dual-channel target speaker extraction based on conditional variational autoencoder and directional information," IEEE/ACM Transactions on Audio, Speech and Language Processing, Vol. 32, pp. 1968-1979, Mar. 2024.</li>
                <li>[2023] R. Wang, B. N. Khanh, D. Morikawa, and M. Unoki, "Method of estimating three dimensional direction-of-arrival based on monaural modulation spectrum," Applied Acoustics, 203, 109215, 9 pages, Feb. 2023.</li>
            </ul>

            <h3>Conference Papers</h3>
            <ul>
                <li>[2023] R. Wang, T. Toda, "Directional target speaker extraction under noisy underdetermined conditions through conditional variational autoencoder with global style tokens," Proc. IEEE WASPAA, New Paltz, USA, Oct. 2023, pp. 1-5.</li>
                <li>[2022] R. Wang, L. Li, and T. Tomoki, "Direction-aware target speaker extraction with a dual-channel system based on conditional variational autoencoders under underdetermined conditions," in Proc. IEEE Asia-Pacific Signal Inf. Process. Assoc. Annu. Summit Conf., 2022, pp. 347-354.</li>
                <li>[2021] N. Li, L. Wang, M. Unoki, S. Li, R. Wang, Me. Ge, J. Dang, "Robust Voice Activity Detection Using a Masked Auditory Encoder Based Convolutional Neural Network," in 2021 IEEE ICASSP, pp. 6828-6832, Jun. 2021.</li>
                <li>[2021] R. Wang, B. N. Khanh, D. Morikawa, and M. Unoki, "Method of Estimating 3D DOA based on Monaural Modulation Spectrum," In: 2021 RISP NCSP, pp. 137-140, Mar. 2021.</li>
            </ul>

            <h3>Other Papers</h3>
            <ul>
                <li>[2022] R. Wang, Li Li, and T. Toda, "Direction-aware target speaker extraction with conditional variational autoencoders and its sensitivity to direction-of-arrival error," 日本音学会春季研究表会演文集, 2-2-6, pp. 195-196, Sep. 2022.</li>
                <li>[2022] R. Wang, L. Li, T. Toda, "Target speaker extraction based on conditional variational autoencoder and directional information in underdetermined condition", Technical Report of IEICE, Vol. 121, No. 383, EA2021-76, pp. 76-81, Mar. 2022.</li>
                <li>[2021] R. Wang, B. N. Khanh, D. Morikawa, and M. Unoki, "Method of estimating DOA based on monaural modulation spectrum," 日本音学会春季研究表会演文集, 3-1-21, pp. 321-324, Mar. 2021.</li>
            </ul>

            <h3>Awards</h3>
            <ul>
                <li>[2023] IEEE WASPAA 2023 Travel Grants.</li>
                <li>[2022] Acoustical Society of Japan (ASJ)-Student paper award.</li>
                <li>[2021] Acoustical Society of Japan (ASJ)-Student paper award (Hokuriku branch).</li>
                <li>[2021] RISP International Workshop on Nonlinear Circuits, Communications and Signal Processing (NCSP)-Student paper award.</li>
            </ul>
        </section>
    </div>
</body>
</html>
